{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo: Limpieza y procesamiento básico de textos\n",
    "**Autor:** Unidad de Científicos de Datos (UCD)\n",
    "\n",
    "---\n",
    "Este ejemplo muestra las principales funcionalidades del módulo `limpieza`, de la librería **ConTexto**. También se muestran ejemplos de uso de las funciones de limpieza contenidas en el módulo auxiliar `limpieza_aux`, que hace parte de `utils`.\n",
    "\n",
    "Para mayor información sobre estos módulos y sus funciones, se puede consultar [su documentación](link de la página de docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## 1. Funciones de limpieza de textos\n",
    "\n",
    "En esta sección se muestra cómo se pueden hacer distintos procesamientos de un texto de entrada para remover elementos como signos de puntuación, *stopwords*, números y acentos, que pueden llegar a entorpecer el análisis de un conjunto de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importar módulo de ConTexto y definir texto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contexto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5a9cf379eec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcontexto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimpieza\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m texto_prueba = '''hola, esto es una prueba para verificar que la limpieza\n\u001b[0;32m      4\u001b[0m \u001b[0msea\u001b[0m \u001b[0mhecha\u001b[0m \u001b[0mcon\u001b[0m \u001b[0mprecisión\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempeño\u001b[0m \u001b[0my\u001b[0m \u001b[0mcalidad\u001b[0m\u001b[0;31m!\u001b[0m \u001b[0mEsperamos\u001b[0m \u001b[0mque\u001b[0m \u001b[0mesté\u001b[0m \u001b[0mtodo\u001b[0m \u001b[0mde\u001b[0m \u001b[1;36m10.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contexto'"
     ]
    }
   ],
   "source": [
    "from contexto.limpieza import *\n",
    "\n",
    "texto_prueba = '''hola, esto es una prueba para verificar que la limpieza\n",
    "sea hecha con precisión, empeño y calidad! Esperamos que esté todo de 10.\n",
    "\n",
    "Desde Amazonas hasta la Guajira y san andrés, desde John y María hasta Ernesto,\n",
    "esperamos       que todo funcione de manera correcta.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Aplicar funciones de limpieza de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza básica, se pasa todo a minúsculas y se eliminan signos de puntuación\n",
    "limpio_basico = limpieza_basica(texto_prueba)\n",
    "\n",
    "# Si se desea mantener los caracteres numéricos\n",
    "limpio_basico_nums = limpieza_basica(texto_prueba, quitar_numeros=False)\n",
    "\n",
    "# Para quitar acentos (diéresis, tildes y virgulillas)\n",
    "sin_acentos = remover_acentos(limpio_basico)\n",
    "\n",
    "# Quitar palabras con menos de 4 caracteres\n",
    "quitar_0a3_caracteres = remover_palabras_cortas(sin_acentos, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la función `limpieza_texto` se puede, a la vez:\n",
    "\n",
    "* Pasar todo el texto a minúsculas\n",
    "* Quitar signos de puntuación\n",
    "* Quitar *stopwords* (palabras y/o expresiones). Para esto, se pueden pasar directamente las listas de palabras y expresiones a quitar, o se puede pasar un archivo que contenga esta información.\n",
    "* Quitar palabras de una longitud menor a *n* caracteres (configurable)\n",
    "* Quitar números (configurable)\n",
    "* Quitar acentos (configurable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limpio_completo = limpieza_texto(texto_prueba, ubicacion_archivo='in/stopwords_prueba.txt', n_min=3)\n",
    "print(limpio_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Quitar elementos repetidos de un texto\n",
    "\n",
    "La función `quitar_repetidos` permite quitar elementos repetidos de un texto, de acuerdo a un separador definido por el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_repetido = 'hola, hola, como estas,hola, hola tu'\n",
    "\n",
    "# Aplicar función directamente\n",
    "quitar_repetidos(texto_repetido)\n",
    "\n",
    "# Especificar el separador entre documentos/frases\n",
    "quitar_repetidos(texto_repetido, ',')\n",
    "\n",
    "# Deshabilitar opción de quitar espacios al inicio y al final\n",
    "quitar_repetidos(texto_repetido, ',', remover_espacios=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Cargar listas de *stopwords*, predefinidas y definidas por el usuario\n",
    "\n",
    "**ConTexto** trae algunas listas predefinidas de *stopwords* que pueden ser cargadas y utilizadas directamente. Las listas incluidas son:\n",
    "\n",
    "* Palabras comunes del lenguaje castellano (solo palabras)\n",
    "* Nombres comunes de hombres y mujeres (solo palabras)\n",
    "* Nombres de municipios y departamentos de Colombia (palabras y expresiones: nombres compuestos como \"San Andrés\")\n",
    "\n",
    "Además de estas listas, la función `lista_stopwords` permite cargar listas predefinidas de las *stopwords* más comunes para varios lenguajes, utilizando la librería NLTK.\n",
    "\n",
    "Finalmente, la función `cargar_stopwords` permite al usuario cargar *stopwords* (tanto palabras como expresiones) desde un archivo plano. Las palabras/expresiones deben ir separadas por comas o ir en renglones separados para ser tenidas en cuenta por aparte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar listas de stopwords predefinidas\n",
    "nombres_hombres = lista_nombres('hombre')\n",
    "nombres_mujeres = lista_nombres('mujer')\n",
    "nombres_todos = lista_nombres()\n",
    "apellidos = lista_apellidos()\n",
    "municipios = lista_geo_colombia('municipios')\n",
    "departamentos = lista_geo_colombia('departamentos')\n",
    "todos_geo = lista_geo_colombia()\n",
    "\n",
    "# Stopwords comunes de varios lenguajes (por defecto se devuelven las de español)\n",
    "stopwords = lista_stopwords()\n",
    "stopwords_ingles = lista_stopwords('ingles')\n",
    "\n",
    "# Cargar archivo con lista de términos y expresiones que se desean remover\n",
    "custom_sw = cargar_stopwords('entrada/stopwords_prueba.txt')\n",
    "print(custom_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## 2. Funciones auxiliares para limpieza de textos\n",
    "\n",
    "Adicionalmente, el módulo auxiliar `limpieza_aux` contiene algunas funciones complementarias que permiten identificar y remover elementos adicionales que puedan entorpecer el análisis de un conjunto de textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importar funciones auxiliares y definir textos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contexto.utils.limpieza_aux import substrings_en_comun, detectar_coincidencias\n",
    "from contexto.utils.limpieza_aux import caracteres_repetidos, caracteres_consecutivos, consonantes_consecutivas\n",
    "from contexto.utils.limpieza_aux import quitar_coincidenias, quitar_palabras_atipicas\n",
    "\n",
    "# Corpus de prueba\n",
    "textos_prueba = [\n",
    "    'Este es el primer texto de prueba para la detección de coincidencias.',\n",
    "    'Una segunda oración permite evaluar si hay cadanea de caracteres elementos en común.',\n",
    "    'Tercera frase que consiste en un texto complementario con palabras comúnmente utilizadas.',\n",
    "    'En esta oración y la siguiente se introducen elementos para completar un grupo de por lo menos 5.',\n",
    "    'Finalmente, esta frase cierra un grupo de 5 oraciones para probar la detección de coincidencias.',\n",
    "    'Una última frase para ampliar un poco el grupo.']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Detectar y quitar coincidencias entre un conjunto de textos\n",
    "\n",
    "En ocasiones un documento puede tener un encabezado o pie de nota común en casi todas sus páginas. Esto puede entorpecer ciertos análisis, al darle un peso demasiado grande a estas coincidencias.\n",
    "\n",
    "Para evitar este problema, la función `quitar_coincidenias` (que a su vez utiliza las funciones `substrings_en_comun` y `detectar_coincidencias`) permite, para un conjunto de textos, encontrar y remover coincidencias (cadenas de caracteres) que cumplan una o varias de estas condiciones:\n",
    "\n",
    "* Que aparezcan en mínimo una proporción determinada de todos los textos\n",
    "* Que su longitud (cantidad de caracteres) sea mayor o igual a un valor determinado\n",
    "* Que la cadena tenga un número de palabras mayor o igual a un valor determinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'substrings_en_comun' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0d3a08ea579c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Detectar coincidencias de por lo menos 4 y 10 caracteres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubstrings_en_comun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextos_prueba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextos_prueba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongitud_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubstrings_en_comun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextos_prueba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtextos_prueba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongitud_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Detectar cadenas de caracteres de mínimo 2 palabras que estén en mínimo la mitad de los textos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'substrings_en_comun' is not defined"
     ]
    }
   ],
   "source": [
    "# Detectar coincidencias de por lo menos 4 y 10 caracteres\n",
    "print(substrings_en_comun(textos_prueba[4], textos_prueba[5], longitud_min=4))\n",
    "print(substrings_en_comun(textos_prueba[4], textos_prueba[5], longitud_min=10))\n",
    "\n",
    "# Detectar cadenas de caracteres de mínimo 2 palabras que estén en mínimo la mitad de los textos\n",
    "print(detectar_coincidencias(textos_prueba, prop=0.5, n_min=2, longitud_min=5))\n",
    "\n",
    "# Quitar las coincidencias encontradas\n",
    "print(quitar_coincidenias(textos_prueba, prop=0.5, n_min=2, longitud_min=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Detectar y quitar palabras o valores atípicos\n",
    "\n",
    "Si se está trabajando con un texto de mala calidad (por ejemplo, porque se aplicó OCR a un documento antiguo y mal escaneado), es posible que haya \"ruido\" en el texto, como palabras sin sentido, que puede afectar el análisis de este documento. Otro caso posible es trabajar con textos que tengan palabras o valores numéricos sospechosos (como \"abcde\" o \"0000000\"). En este caso, puede ser de utilidad poder detectar y/o remover estas palabras sospechosas o de ruido.\n",
    "\n",
    "Para evitar este problema, la función `quitar_palabras_atipicas` (que a su vez utiliza las funciones `caracteres_repetidos`, `caracteres_consecutivos` y `consonantes_consecutivas`) permite, para un conjunto de textos, encontrar y remover palabras que cumplan una o varias de estas condiciones:\n",
    "\n",
    "* Que tengan un número o letra repetidos de forma seguida más veces de lo permitido\n",
    "* Que tengan números o letras consecutivas de forma seguida en un número mayor de lo permitido\n",
    "* Que tengan más consonantes seguidas de lo permitido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si una palabra tiene una cantidad determinada de caracteres repetidos seguidos\n",
    "caracteres_repetidos('123444321', 4)\n",
    "# La función por defecto quita acentos y pasa todo a minúsculas, para que esto no afecte la búsqueda de repetidos\n",
    "caracteres_repetidos('GóOol', 3)\n",
    "\n",
    "# Detectar si una palabra tiene una cantidad determinada de caracteres consecutivos seguidos\n",
    "caracteres_consecutivos('123444321', 4)\n",
    "caracteres_consecutivos('aBCdE', 4)\n",
    "\n",
    "# Detectar si una palabra tiene una cantidad determinada de consonantes seguidas\n",
    "consonantes_consecutivas('AbStracto', 3)\n",
    "consonantes_consecutivas('Lynyrd Skynyrd', 4)\n",
    "# El resultado cambia si se deja de incluir la letra \"Y\" como vocal\n",
    "consonantes_consecutivas('Lynyrd Skynyrd', 4, incluir_y=False)\n",
    "# La función quita acentos por defecto, por lo que puede trabajar con consonantes que tengan algún tipo de acento o tilde\n",
    "consonantes_consecutivas('mñçs', 4)\n",
    "\n",
    "# Prueba de quitar palabras con problemas en un texto\n",
    "texto_prueba = 'HolaAá! esta es una pruebba para ver si, En 12345, se pueden abstraer las reglas del abcdario.'\n",
    "\n",
    "texto_sin_atipicas = quitar_palabras_atipicas(texto_prueba, n_repetidas=3, n_consecutivas=3, n_consonantes=4)\n",
    "\n",
    "print(f\"---------------\\nTexto original:\\n{texto_prueba}\")\n",
    "print(f\"---------------\\nTexto sin palabras detectadas como atípicas:\\n{texto_sin_atipicas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
